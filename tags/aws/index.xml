<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on Go slowly</title>
    <link>https://manhtai.github.io/tags/aws/</link>
    <description>Recent content in AWS on Go slowly</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jan 2023 22:49:31 +0700</lastBuildDate>
    
        <atom:link href="https://manhtai.github.io/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>S3 Setup for Serving Public Content</title>
      <link>https://manhtai.github.io/posts/s3-setup-for-serving-public-content/</link>
      <pubDate>Fri, 13 Jan 2023 22:49:31 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/s3-setup-for-serving-public-content/</guid>
      <description>&lt;h2 id=&#34;iam-policy&#34;&gt;IAM policy&lt;/h2&gt;
&lt;p&gt;Create a specific IAM user to interact with S3 bucket, and Cloudfront if you
use a CDN:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2012-10-17&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Statement&amp;#34;&lt;/span&gt;: [
        {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Action&amp;#34;&lt;/span&gt;: [
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s3:*&amp;#34;&lt;/span&gt;
            ],
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Resource&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arn:aws:s3:::assets.example.com/*&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Effect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Allow&amp;#34;&lt;/span&gt;
        },
        {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Action&amp;#34;&lt;/span&gt;: [
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cloudfront:CreateInvalidation&amp;#34;&lt;/span&gt;
            ],
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Resource&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Effect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Allow&amp;#34;&lt;/span&gt;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;bucket-policy&#34;&gt;Bucket policy&lt;/h2&gt;
&lt;p&gt;You should allow public objects, ACLs, and add a get public object policy for
the bucket:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2008-10-17&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Statement&amp;#34;&lt;/span&gt;: [
        {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Sid&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PublicReadGetObject&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Effect&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Allow&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Principal&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Action&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s3:GetObject&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Resource&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arn:aws:s3:::assets.example.com/*&amp;#34;&lt;/span&gt;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;bucket-cors&#34;&gt;Bucket CORS&lt;/h2&gt;
&lt;p&gt;Allow CORS if you intend to use your assets cross domains:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;[
    {
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;AllowedHeaders&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;AllowedMethods&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GET&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PUT&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;HEAD&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POST&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DELETE&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;AllowedOrigins&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;ExposeHeaders&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ETag&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;MaxAgeSeconds&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;3000&lt;/span&gt;
    }
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Upgrade Postgres major version with near-zero-downtime</title>
      <link>https://manhtai.github.io/posts/upgrade-postgres-major-version-with-near-zero-downtime/</link>
      <pubDate>Mon, 20 Jun 2022 07:32:27 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/upgrade-postgres-major-version-with-near-zero-downtime/</guid>
      <description>&lt;p&gt;Our system have a typical facing API and some workers which do jobs on the
background. All of them have read/write access to the Postgres instance. Our
instance is not very big, but when we try to upgrade using AWS console on the
clone, it takes more than 20 minutes and that&amp;rsquo;s not acceptable.
Hence we were looking elsewhere, and find &lt;a href=&#34;https://aws.amazon.com/blogs/database/achieving-minimum-downtime-for-major-version-upgrades-in-amazon-aurora-for-postgresql-using-aws-dms/&#34;&gt;a solution&lt;/a&gt; from AWS using DMS.
It worked out pretty well for us.&lt;/p&gt;
&lt;h2 id=&#34;step-by-step&#34;&gt;Step by step&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Clone a new instance from our current database, truncate all tables and
upgrade the new database to the latest version.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Full load and then CDC sync between the old database and the new one.
Monitor the latency as well as table statistics.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop all writing tasks (API &amp;amp; workers) to old database.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop DMS job.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Switch database connection to the new one and restart all writing tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify, then clean up old resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;catches&#34;&gt;Catches&lt;/h2&gt;
&lt;p&gt;Current DMS engine (3.4.6) has some problems with some column types. But we
can resolve them quickly thanks to clear error logs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;varchar&lt;/code&gt; (without n), we have to convert it to &lt;code&gt;text&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;jsonb not null&lt;/code&gt;, we have to make it nullable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But in overall the upgrade process is smooth, we still got some downtime but
it&amp;rsquo;s insignificant.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Redshift for customer-facing apps</title>
      <link>https://manhtai.github.io/posts/redshift-as-a-database-for-customer-facing-app/</link>
      <pubDate>Wed, 02 Mar 2022 19:08:23 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/redshift-as-a-database-for-customer-facing-app/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/redshift/&#34;&gt;Redshift&lt;/a&gt; is an OLAP database from AWS, so for data warehouse purpose, it&amp;rsquo;s
a viable option. The question is, can we use it as an OLTP database for
customer-facing applications?&lt;/p&gt;
&lt;p&gt;Short answer: No, for generic OLTP use case, and Yes for specific functions,
such as analytics or building dashboards. The reasons are, firstly, analytic
jobs usually do aggregation on a large chunk of data which would run very slow
on row-based OLTP databases, and secondly, analytic features are usually the
low traffic parts on the system. Those requirements align very well with
Redshift features.&lt;/p&gt;
&lt;h2 id=&#34;1-concurrency-connections&#34;&gt;1. Concurrency connections&lt;/h2&gt;
&lt;p&gt;As of now, Redshift &lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/cm-c-defining-query-queues.html#cm-c-defining-query-queues-concurrency-level&#34;&gt;supports&lt;/a&gt; up to 50 concurrency connections by default.
Although we can get &lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/concurrency-scaling.html&#34;&gt;concurrency scaling&lt;/a&gt; feature by paying more, we need
to keep the query latency in the 1-5 seconds range to be usable. Let&amp;rsquo;s say we
get an average of 1 second per query, then we can serve up to 50 requests per
second (RPS), if the analytic APIs only serve 10 RPS, then we&amp;rsquo;re good to go.&lt;/p&gt;
&lt;h2 id=&#34;2-query-latency&#34;&gt;2. Query latency&lt;/h2&gt;
&lt;p&gt;The catch now is how will we keep our query latency to only seconds, or
even better, sub-second? Redshift is very powerful, but for a huge amount of
data, it must be tuned correctly for fast queries.&lt;/p&gt;
&lt;p&gt;Enter the Redshift&amp;rsquo;s DIST key and SORT key couple!&lt;/p&gt;
&lt;p&gt;Since Redshift is a columnar database and is designed to keep a massive
volume, it doesn&amp;rsquo;t have indexes as normal database, it only has 2 kinds of
key for distributing and sorting data into desired locations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DIST key: for distributing data between compute nodes. It will affect
joins and aggregations performance. We should choose a high cardinality
column for this key.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SORT key: for sorting data on disk. It will affect your &amp;ldquo;where&amp;rdquo; performance.
There are 2 types of sort key: COMPOUND and INTERLEAVED, but we can only
choose only one of them for the table sort key.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Refer to AWS best practice for designing table &lt;a href=&#34;https://docs.aws.amazon.com/redshift/latest/dg/c_designing-tables-best-practices.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;3-benchmark&#34;&gt;3. Benchmark&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve done some benchmarks using &lt;a href=&#34;https://k6.io/&#34;&gt;k6&lt;/a&gt; on our toy APIs that use Redshift
ra3.xlplus (4 vCPU, 32 GB RAM, 3 compute nodes) with ~1TB of data in each
table, as the main database and the results are as good as promised: if you
keep your query latency to 1 second, you get 50 RPS, if it goes down to 500
ms, you get 100 RPS.&lt;/p&gt;
&lt;p&gt;The math works out!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Restart Golang Goroutines</title>
      <link>https://manhtai.github.io/posts/restart-golang-goroutines/</link>
      <pubDate>Fri, 12 Nov 2021 10:48:34 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/restart-golang-goroutines/</guid>
      <description>&lt;p&gt;In some cases such as &lt;a href=&#34;https://manhtai.github.io/posts/distribute-workload-in-ecs-tasks&#34;&gt;distributing the workload between ECS tasks&lt;/a&gt;, we need to
restart our workers, which are Goroutines in our case, base on the number of
ECS tasks to reassign partitions to the Goroutines on the same task.&lt;/p&gt;
&lt;p&gt;Suppose we got 100 database partitions, if we had 1 ECS task, then all the
workers on that task will be responsible for all 100 partitions. But when we
scale the service to 20 ECS tasks, each task will be responsible for only
5 partitions, hence we need to restart the Goroutines and assign them
5 partitions only.&lt;/p&gt;
&lt;p&gt;How would we do that? Here it is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;w&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;worker&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;run&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;ctx&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;context&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Context&lt;/span&gt;) {
	&lt;span style=&#34;color:#a6e22e&#34;&gt;partitions&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; make(&lt;span style=&#34;color:#66d9ef&#34;&gt;chan&lt;/span&gt; []&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;)

	&lt;span style=&#34;color:#75715e&#34;&gt;// Partition worker
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;go&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;w&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;partitionWorker&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;start&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;ctx&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;partitions&lt;/span&gt;)

	&lt;span style=&#34;color:#75715e&#34;&gt;// Variable to cancel context
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;	&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;partCtx&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;context&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Context&lt;/span&gt;
	&lt;span style=&#34;color:#a6e22e&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;partCancel&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;context&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;WithCancel&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;ctx&lt;/span&gt;)

	&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; {
		&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; {
		&lt;span style=&#34;color:#66d9ef&#34;&gt;case&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;parts&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;partitions&lt;/span&gt;:
			&lt;span style=&#34;color:#a6e22e&#34;&gt;partCancel&lt;/span&gt;()
			&lt;span style=&#34;color:#a6e22e&#34;&gt;partCtx&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;partCancel&lt;/span&gt; = &lt;span style=&#34;color:#a6e22e&#34;&gt;context&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;WithCancel&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;context&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;TODO&lt;/span&gt;())
			&lt;span style=&#34;color:#66d9ef&#34;&gt;go&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;w&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;jobWorker&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;start&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;partCtx&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;parts&lt;/span&gt;)

		&lt;span style=&#34;color:#66d9ef&#34;&gt;case&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;ctx&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Done&lt;/span&gt;():
			&lt;span style=&#34;color:#a6e22e&#34;&gt;partCancel&lt;/span&gt;()
			&lt;span style=&#34;color:#75715e&#34;&gt;// Wait for jobWorker to finish
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;			&lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Sleep&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Second&lt;/span&gt;)
			&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;
		}
	}
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;partitionWorker&lt;/code&gt; is in charge of determining the partitions that the current
ECS tasks need to work on, see the guide on how to do it &lt;a href=&#34;https://manhtai.github.io/posts/distribute-workload-in-ecs-tasks&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;jobWorker&lt;/code&gt; is the one that does the heavy lifting on specific partitions
and will be restarted whenever the partitions change.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Distribute workload between ECS tasks</title>
      <link>https://manhtai.github.io/posts/distribute-workload-in-ecs-tasks/</link>
      <pubDate>Thu, 19 Aug 2021 14:04:41 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/distribute-workload-in-ecs-tasks/</guid>
      <description>&lt;p&gt;If your ECS tasks are receiving traffic from a load balancer then the workload
will be equally distributed between them. How about when we are using ECS
tasks as a worker farm to handle long running jobs? And say, we want some
workers to work on some partitions of the data but not all of them? Then each
ECS task must know their identity and the number of tasks that belong to the
same service as well.&lt;/p&gt;
&lt;h2 id=&#34;1-get-task-arn&#34;&gt;1. Get task ARN&lt;/h2&gt;
&lt;p&gt;With &lt;code&gt;${ECS_CONTAINER_METADATA_URI_V4}/task&lt;/code&gt; endpoint, we can get the task ARN
and metadata about its cluster and family. The docs are &lt;a href=&#34;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v4.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After sending a GET request from our container, we got:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    &amp;quot;Cluster&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;TaskARN&amp;quot;: &amp;quot;arn:aws:ecs:us-west-2:111122223333:task/default/158d1c8083dd49d6b527399fd6414f5c&amp;quot;,
    &amp;quot;Family&amp;quot;: &amp;quot;curltest&amp;quot;,
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This request doesn&amp;rsquo;t require any authentication at all, as long as we send it
from our ECS task.&lt;/p&gt;
&lt;h2 id=&#34;2-list-all-tasks-in-the-same-service&#34;&gt;2. List all tasks in the same service&lt;/h2&gt;
&lt;p&gt;With &lt;code&gt;Cluster&lt;/code&gt; and &lt;code&gt;Family&lt;/code&gt; of a task, we can list all running tasks in
a service using ECS API, in this example we will use Go SDK though:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Go&#34; data-lang=&#34;Go&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;list&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ecsClient&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;ListTasks&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;context&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;TODO&lt;/span&gt;(), &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;ecs&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;ListTasksInput&lt;/span&gt;{
	&lt;span style=&#34;color:#a6e22e&#34;&gt;Cluster&lt;/span&gt;:       &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;,
	&lt;span style=&#34;color:#a6e22e&#34;&gt;Family&lt;/span&gt;:        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;curltest&amp;#34;&lt;/span&gt;,
	&lt;span style=&#34;color:#a6e22e&#34;&gt;DesiredStatus&lt;/span&gt;: &lt;span style=&#34;color:#a6e22e&#34;&gt;types&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;DesiredStatusRunning&lt;/span&gt;,
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;list.TaskArns&lt;/code&gt; contains all ARN of tasks in the service, including the task
making the request. This request does require authentication nevertheless.&lt;/p&gt;
&lt;h2 id=&#34;3-distribute-the-workload&#34;&gt;3. Distribute the workload&lt;/h2&gt;
&lt;p&gt;Now we know how many tasks we got, the problem becomes &lt;a href=&#34;https://manhtai.github.io/posts/restart-golang-goroutines&#34;&gt;easy&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Design DynamoDB Tables</title>
      <link>https://manhtai.github.io/posts/design-dynamodb-tables/</link>
      <pubDate>Mon, 05 Jul 2021 16:27:58 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/design-dynamodb-tables/</guid>
      <description>&lt;h2 id=&#34;primary-key--indexes&#34;&gt;Primary key &amp;amp; Indexes&lt;/h2&gt;
&lt;p&gt;DynamoDB is a NoSQL database, so in theory, you can store all kinds of
objects. The catch is you can specify the key to partition the data, so
you can scale out your applications horizontally, in proportion to the
numbers of partitions.&lt;/p&gt;
&lt;p&gt;There are two kinds of primary keys in a DynamoDB table, of which you
can only choose to implement one:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hash key only&lt;/strong&gt;: The hash key is also the partition key, which must
be globally unique.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hash key with a range key combination&lt;/strong&gt;: The hash key is the
partition key, which is not required to be unique, but the combination,
i.e. the primary key must be.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Whichever kind of primary key you choose, the scalability is the same.
To make it works, make sure your hash keys are distributed equally in all
partitions.&lt;/p&gt;
&lt;p&gt;Besides the primary key, DynamoDB supports global secondary indexes and local
secondary indexes, so you can make your queries run fast in other dimensions
also.&lt;/p&gt;
&lt;h2 id=&#34;an-example-in-go&#34;&gt;An example in Go&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/guregu/dynamo/&#34;&gt;dynamo&lt;/a&gt; is a Golang library that makes it extremely easy to define the primary
key and indexes.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define a &lt;code&gt;Job&lt;/code&gt; table with a primary key as the combination of &lt;code&gt;ShardId&lt;/code&gt;
and &lt;code&gt;Token&lt;/code&gt;, in which &lt;code&gt;ShardId&lt;/code&gt; is a hash key, and &lt;code&gt;Token&lt;/code&gt; is a range key:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Job&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; {
	&lt;span style=&#34;color:#a6e22e&#34;&gt;ShardId&lt;/span&gt;      &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;               &lt;span style=&#34;color:#e6db74&#34;&gt;`dynamo:&amp;#34;shard_id,hash&amp;#34;`&lt;/span&gt;
	&lt;span style=&#34;color:#a6e22e&#34;&gt;Token&lt;/span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;            &lt;span style=&#34;color:#e6db74&#34;&gt;`dynamo:&amp;#34;date_token,range&amp;#34;`&lt;/span&gt;
	&lt;span style=&#34;color:#a6e22e&#34;&gt;Name&lt;/span&gt;         &lt;span style=&#34;color:#66d9ef&#34;&gt;string&lt;/span&gt;            &lt;span style=&#34;color:#e6db74&#34;&gt;`dynamo:&amp;#34;name&amp;#34;`&lt;/span&gt;
	&lt;span style=&#34;color:#a6e22e&#34;&gt;CreatedAt&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Time&lt;/span&gt;         &lt;span style=&#34;color:#e6db74&#34;&gt;`dynamo:&amp;#34;created_at&amp;#34;`&lt;/span&gt;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now to create the table, we init a DynamoDB session and create the table:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;session&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;session&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;NewSession&lt;/span&gt;()
&lt;span style=&#34;color:#a6e22e&#34;&gt;config&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;aws&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;NewConfig&lt;/span&gt;()
&lt;span style=&#34;color:#a6e22e&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dynamo&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;New&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;session&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;config&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;client&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;CreateTable&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;`Job`&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;Job&lt;/span&gt;{}).&lt;span style=&#34;color:#a6e22e&#34;&gt;Run&lt;/span&gt;()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To query the jobs in a specific shard:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;jobs&lt;/span&gt; []&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;Job&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;client&lt;/span&gt;.
    &lt;span style=&#34;color:#a6e22e&#34;&gt;Table&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;`Job`&lt;/span&gt;).
    &lt;span style=&#34;color:#a6e22e&#34;&gt;Get&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shard_id&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;shardId&lt;/span&gt;).
    &lt;span style=&#34;color:#a6e22e&#34;&gt;Filter&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#39;token&amp;#39; &amp;lt; ?&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;tokenId&lt;/span&gt;).
    &lt;span style=&#34;color:#a6e22e&#34;&gt;Limit&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;).
    &lt;span style=&#34;color:#a6e22e&#34;&gt;All&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;jobs&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Setup CORS for S3 and Cloudfront</title>
      <link>https://manhtai.github.io/posts/setup-cors-for-s3-and-cloudfront/</link>
      <pubDate>Fri, 04 Dec 2020 20:53:21 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/setup-cors-for-s3-and-cloudfront/</guid>
      <description>&lt;p&gt;CORS problem arises in one of our apps because static files return from
CloudFront do not allow CORS. Specifically, they do not return following
header:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;Access-Control-Allow-Origin: *
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The problem is, we&amp;rsquo;ve setup CloudFront and S3 to support CORS as mentioned in
&lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html&#34;&gt;the docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In S3 bucket rules, we have:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;[
    {
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;AllowedHeaders&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Authorization&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;AllowedMethods&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GET&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;AllowedOrigins&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;ExposeHeaders&amp;#34;&lt;/span&gt;: [],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;MaxAgeSeconds&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;20000&lt;/span&gt;
    }
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In CloudFront, we have:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;Cache and origin request settings: Use a cache policy and origin request policy
Cache Policy                     : Managed-CachingOptimized
Origin Request Policy            : Managed-CORS-S3Origin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;All looks good, but our problem persists.&lt;/p&gt;
&lt;p&gt;Continue following &lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html&#34;&gt;the docs&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How does Amazon S3 evaluate the CORS configuration on a bucket?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;When Amazon S3 receives a preflight request from a browser, it evaluates the
CORS configuration for the bucket and uses the first CORSRule rule that matches
the incoming browser request to enable a cross-origin request. For a rule to
match, the following conditions must be met:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The request&amp;rsquo;s Origin header must match an AllowedOrigin element.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The request method (for example, GET or PUT) or the Access-Control-Request-Method
header in case of a preflight OPTIONS request must be one of the AllowedMethod elements.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Every header listed in the request&amp;rsquo;s Access-Control-Request-Headers header on the
preflight request must match an AllowedHeader element.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We inspect the GET request that the browser makes to get the static files and
observe that the request header does not include &lt;code&gt;Origin&lt;/code&gt; in the first request
send to CloudFront, and CloudFront does not send back
&lt;code&gt;Access-Control-Allow-Origin&lt;/code&gt; header.&lt;/p&gt;
&lt;p&gt;After the first request, CloudFront will cache the response header, and even
if the browser send the &lt;code&gt;Origin&lt;/code&gt; request header next time, it still does not send back
&lt;code&gt;Access-Control-Allow-Origin&lt;/code&gt; response header.&lt;/p&gt;
&lt;p&gt;The solution is quite simple than we thought, we create a new cache policy with
&lt;code&gt;Origin&lt;/code&gt; be one of the cache keys (the only different one from &lt;code&gt;Managed-CachingOptimized&lt;/code&gt;
policy), then the problem goes away.&lt;/p&gt;
&lt;p&gt;This works fine if the origin number is small as in our case.&lt;/p&gt;
&lt;p&gt;There are two other ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1, Use Lambda@Edge to set the necessary header.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2, Override origin header from CloudFront to a dummy one.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2, feels a little bit hacky but it might be the best solution.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Drain ECS instances before scaling down in EC2</title>
      <link>https://manhtai.github.io/posts/drain-ecs-before-scaling-in-ec2/</link>
      <pubDate>Mon, 21 May 2018 17:33:18 +0700</pubDate>
      
      <guid>https://manhtai.github.io/posts/drain-ecs-before-scaling-in-ec2/</guid>
      <description>&lt;h2 id=&#34;the-problem&#34;&gt;The problem&lt;/h2&gt;
&lt;p&gt;We have 2 independent auto scaling systems: EC2 auto scaling groups which
scales instances number &amp;amp; ECS auto scaling which scales tasks number. This
setup may work fine when scaling up. Still, if new tasks need more instances
to start up, it must wait for them, but it&amp;rsquo;s ok to wait a little.&lt;/p&gt;
&lt;p&gt;But things soon become disaster when EC2 instances terminates &lt;strong&gt;before&lt;/strong&gt;
ECS tasks draining out.&lt;/p&gt;
&lt;p&gt;Actually, ECS instances will not auto drain to be ready for terminating
instances in EC2, so don&amp;rsquo;t expect anything. We have to set that up manually.&lt;/p&gt;
&lt;h2 id=&#34;the-solution&#34;&gt;The solution&lt;/h2&gt;
&lt;p&gt;An AWS official &lt;a href=&#34;https://aws.amazon.com/blogs/compute/how-to-automate-container-instance-draining-in-amazon-ecs/&#34;&gt;blog&lt;/a&gt; shows us how to do this, and it has a nice demo for
newly created EC2 &amp;amp; ECS setup. But what if we just want to set up for our
running ECS instances? Here it is.&lt;/p&gt;
&lt;p&gt;Firstly, make sure you know what &lt;a href=&#34;https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html&#34;&gt;lifecycle hooks&lt;/a&gt; are. Then follow these
steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1, Create a lambda function using this &lt;a href=&#34;https://gist.github.com/manhtai/66dfdae56ebce7b6270788018516a409&#34;&gt;script&lt;/a&gt;. It is my fork of AWS
sample &lt;a href=&#34;https://github.com/aws-samples/ecs-cid-sample/blob/master/code/index.py&#34;&gt;script&lt;/a&gt;, but sucks less.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2, Set role for our lambda function to have these permissions:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;- autoscaling:CompleteLifecycleAction
- logs:CreateLogGroup
- logs:CreateLogStream
- logs:PutLogEvents
- ec2:DescribeInstances
- ec2:DescribeInstanceAttribute
- ec2:DescribeInstanceStatus
- ec2:DescribeHosts
- ecs:ListContainerInstances
- ecs:SubmitContainerStateChange
- ecs:SubmitTaskStateChange
- ecs:DescribeContainerInstances
- ecs:UpdateContainerInstancesState
- ecs:ListTasks
- ecs:DescribeTasks
- sns:Publish
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;3, Setup an SNS trigger for the function, choose a name for it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4, Setup a service role so Auto Scaling Groups can push to SNS, using &lt;a href=&#34;https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html#sns-notifications&#34;&gt;this
guide&lt;/a&gt;. (This is quite interesting because you have to set up a role so
that a service will have some kind of permission).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5, Create a lifecycle hook by CLI, since the &lt;strong&gt;GUI is not fully supported
yet&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;aws autoscaling put-lifecycle-hook
  --lifecycle-hook-name EcsWebScaleDown
  --auto-scaling-group-name ecs-web
  --lifecycle-transition autoscaling:EC2_INSTANCE_TERMINATING
  --heartbeat-timeout 900
  --notification-target-arn arn:aws:sns:ap-southeast-1:XXXXXXXXXXXX:EcsInstanceDrain
  --role-arn arn:aws:iam::XXXXXXXXXXXX:role/AutoScalingNotificationRole
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It should be good now, as advertised :)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>